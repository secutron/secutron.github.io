---
title: discriminative vs generative
category: generative model
tag: [discriminative, generative]
---

이번 글에서는 **discriminative model**과 **generative model**을 비교해보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.





## discriminative model

*discriminative model*이란 데이터 $X$가 주어졌을 때 레이블 $Y$가 나타날 조건부확률 $p(Y$\|$X)$를 직접적으로 반환하는 모델을 가리킵니다. 레이블 정보가 있어야 하기 때문에 지도학습(supervised learning) 범주에 속하며 $X$의 레이블을 잘 구분하는 **결정경계(decision boundary)**를 학습하는 것이 목표가 됩니다. *discriminative model*은 [generative model]()에 비해 가정이 단순하고, 학습데이터 양이 충분하다면 좋은 성능을 내는 것으로 알려져 있습니다. 선형회귀와 로지스틱회귀는 *disciminative model*의 대표적인 예시입니다.



## generative model

*generative model*이란 데이터 $X$가 생성되는 과정을 두 개의 확률모형, 즉 $p(Y)$, $p(X$\|$Y)$으로 정의하고, 베이즈룰을 사용해 $p(Y$\|$X)$를 간접적으로 도출하는 모델을 가리킵니다. *generative model*은 레이블 정보가 있어도 되고, 없어도 구축할 수 있습니다. 전자를 [지도학습기반의 *generative model*]()이라고 하며 [선형판별분석](https://ratsgo.github.io/machine%20learning/2017/03/21/LDA/)이 대표적인 사례입니다. 후자는 [비지도학습 기반의 *generative model*]()이라고 하며 가우시안믹스처모델, [토픽모델링](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/06/01/LDA/)이 대표적인 사례입니다.

*generative model*은 *discriminative model*에 비해 가정이 많습니다. 그 가정이 실제 현상과 맞지 않는다면 *generative model*의 성능은 *discriminative model*보다 성능이 좋지 않을 수 있지만, 가정이 잘 구축되어 있다면 이상치에도 강건하고 학습데이터가 적은 상황에서도 좋은 예측 성능을 보일 수 있습니다. *generative model*은 **범주의 분포(distribution)**을 학습하는 것이 목표가 됩니다. 또한 *generative model*은 일반적인 [베이지안 추론](https://ratsgo.github.io/statistics/2017/06/30/bayesinfer/)과 마찬가지로 학습데이터가 많을 수록 *discriminative model*과 비슷한 성능으로 수렴하는 경향이 있다고 합니다. 아울러 *generative model*은 $p(X$\|$Y)$을 구축하기 때문에 이 모델을 활용해 $X$를 샘플링할 수도 있습니다.





## data distribution

여기에서 '데이터의 분포'라는 개념이 아리송합니다. 예를 들어보겠습니다. 우리가 가진 데이터가 사람 얼굴 사진이라고 칩시다. 이미지 크기가 64×64×3이라면 우리의 데이터($x$)는 이만한 크기의 벡터들일 것입니다. 이 사진(벡터)들을 어떤 기준에 따라 일렬로 세웠다고 가정해 보겠습니다.



<a href="https://imgur.com/FVhbZOx"><img src="https://i.imgur.com/FVhbZOx.png" width="500px" title="source: imgur.com" /></a>



우리가 가지고 있는 사진 데이터셋이 동양인들 중심이라면 검은 머리색을 하고 있는 사진이 나타날 확률은 꽤 높을 수 있습니다. 바꿔 말해 검은 머리색을 하고 있는 사진들을 $x$축에 표시하면 $x_3$ 언저리에 위치하고 $p_{data}(x_3)$은 가장 높은 값을 가지게 될 것이라는 얘기입니다. 반대로 머리색이 금발인 사진들이 $x_4$쯤에 위치하고 $p_{data}(x_4)$는 낮은 값을 가집니다. 더 나아가, 처음 보는 이상한 사진들이라면 발생확률이 0에 가까울 것입니다.

*generative model*의 목적 가운데 하나는 데이터의 분포를 학습하는 것입니다. 다시 말해 우리가 구축하려는 모델에 데이터를 넣으면 실제 데이터의 확률에 가깝게 값을 반환하게끔 만들고 싶다는 이야기입니다. 이를 도식화한 그림은 다음과 같습니다.



<a href="https://imgur.com/ZXQz3r1"><img src="https://i.imgur.com/ZXQz3r1.png" width="400px" title="source: imgur.com" /></a>







## Deep Generative Model

*Deep Generative Model*이란 딥러닝을 활용한 *generative model*입니다. 데이터의 분포(distribution)를 학습하고, 이로부터 새로운 데이터 $X$를 생성하는 것이 목적입니다. 딥러닝은 데이터의 분포를 모사하거나, 벡터 간 변환에 뛰어난 성능을 지니기 때문에 최근 *generative model*에 딥러닝 기법이 널리 쓰이고 있습니다. *Deep Generative Model*을 도식화한 그림은 다음과 같습니다.



<a href="https://imgur.com/SgRIzIP"><img src="https://i.imgur.com/SgRIzIP.png" width="500px" title="source: imgur.com" /></a>





## 차이

다음 그림들은 *disciriminative model*과 *generative model* 간 차이를 직관적으로 나타낸 것입니다.



<a href="https://imgur.com/4leE3wr"><img src="https://i.imgur.com/4leE3wr.jpg" width="400px" title="source: imgur.com" /></a>

*generative model은 사후확률을 간접적으로, disciriminative model은 직접적으로 도출한다.*



<a href="https://imgur.com/alus0zQ"><img src="https://i.imgur.com/alus0zQ.png" width="400px" title="source: imgur.com" /></a>

*generative model은 데이터 범주의 분포를, disciriminative model은 결정경계를 학습한다.*



