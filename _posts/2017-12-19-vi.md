---
title: 변분추론(Variational Inference)
category: generative model
tag: [Variational Inference]
---

이번 글에서는 **Variational Inference**(변분추론, 이하 VI)에 대해 살펴보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의와 위키피디아 등을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.





## concept

VI란 사후확률(posterior) 분포 $p(z$\|$x)$를 다루기 쉬운 확률분포 $q(z)$로 근사(approximation)하는 걸 말합니다. 사후확률 분포를 계산하는게 불가능에 가까울 정도로 어려운 경우가 많기 때문입니다. 가령 다음과 같은 경우입니다.

- *marginal probability*, 즉 사후확률의 분모인 $p(x)=Σ_zp(x,z)$를 계산하기 힘든 경우
- *likelihood*, 즉 $p(x$\|$z)$를 더 복잡하게 모델링하고 싶은 경우
- *prior*, 즉 $p(z)$를 더 복잡하게 모델링하고 싶은 경우

VI를 도식화한 그림은 아래와 같습니다. 사후확률 분포를 우리가 익히 알고 있는 정규분포로 근사한 케이스입니다.

<a href="https://imgur.com/05LNq0o"><img src="https://i.imgur.com/05LNq0o.png" width="350px" title="source: imgur.com" /></a>



## KL Divergence

사후확률에 근사한 $q(z)$를 만들기 위해 [쿨백-라이블러 발산(Kullback-Leibler divergence, 이하 KLD)](https://ratsgo.github.io/statistics/2017/09/22/information/) 개념을 활용합니다. KLD는 두 확률분포의 차이를 계산하는 데 사용하는 함수인데요. 사후확률 분포 $p(z$\|$x)$와 $q(z)$ 사이의 KLD를 계산하고, KLD가 줄어드는 쪽으로 $q(z)$를 조금씩 업데이트하는 과정을 반복하면 사후확률을 잘 근사하는 $q^*(z)$를 얻게 될 것이라는 게 VI의 핵심 아이디어입니다. KLD 식을 조금 변형하면 다음과 같이 유도할 수 있습니다.


$$
\begin{align*}
{ D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right)  \right) =&\int { q\left( z \right) \log { \frac { q\left( z \right)  }{ p\left( z|x \right)  }  } dz } \\ =&\int { q\left( z \right) \log { \frac { q\left( z \right) p\left( x \right)  }{ p\left( x|z \right) p\left( z \right)  }  } dz } \\ =&\int { q\left( z \right) \log { \frac { q\left( z \right)  }{ p\left( z \right)  }  } dz } +\int { q\left( z \right) \log { p\left( x \right)  } dz } -\int { q\left( z \right) \log { p(x|z) } dz } \\ =&{ D }_{ KL }\left( q\left( z \right) ||p\left( z \right)  \right) +\log { p\left( x \right)  } -{ E }_{ z\sim q\left( z \right)  }\left[ \log { p(x|z) }  \right] 
\end{align*}
$$


이후 이 글에서는 동전던지기 예제를 바탕으로 VI를 설명하겠습니다.





## conjugate distribution

동전던지기 실험은 **이항분포**를 따릅니다. 이항분포란 성공확률이 $p$이고, 그 결과가 성공 혹은 실패뿐인 실험을 $n$번 반복시행할 때 성공횟수의 분포를 가리킵니다. 이항분포 파라메터 $p$의 사전확률과 사후확률 모두 베타분포를 따르는데요. 이처럼 사전확률 분포와 사후확률 분포가 같은 가족군으로 묶일 때 그 사후확률/사전확률을 모두 묶어 **켤레분포(conjugate distributions)**라고 합니다.

$q(z)$를 $α_q$, $β_q$를 파라메터로 하는 베타분포, 앞면이 관측된 수를 $n_h$, 뒷면을 $n_t$로 둡시다. 이를 아래 식에 대입해 풀면 사후확률 분포 $p(z$\|$x)$에 가장 잘 근사한 $q(z)$는 $α_q+n_h$, $β_q+n_t$를 파라메터로 하는 베타분포가 된다고 합니다. 이와 관련해서는 [이 글](https://ratsgo.github.io/statistics/2017/06/30/bayesinfer/), 수식 유도와 관련해서는 [위키피디아](https://en.wikipedia.org/wiki/Beta_distribution)를 참고하시면 좋을 것 같습니다.






## Variational Inference with Monte Carlo sampling

[몬테카를로 방법(Monte Carlo Method)](https://ratsgo.github.io/statistics/2017/05/31/gibbs/)이란 랜덤 표본을 뽑아 함수의 값을 확률적으로 계산하는 알고리즘을 가리킵니다. 수학이나 물리학 등에 자주 사용되며 계산하려는 값이 **닫힌 형식**(closed form)으로 표현되지 않거나 복잡한 경우에 그 값을 근사적으로 계산하려고 할 때 쓰입니다. 예컨대 특정 확률 분포를 따르는 $x$의 함수값의 기대값은 다음과 같이 $k$개 샘플로 근사하는 것입니다.


$$
\int { p\left( x \right) f\left( x \right) dx } ={ E }_{ x\sim p\left( x \right)  }\left[ f(x) \right] \approx \frac { 1 }{ K } \sum _{ i=0 }^{ K }{ { \left[ f({ x }_{ i }) \right]  }_{ { x }_{ i }\sim p\left( x \right)  } }
$$


몬테카를로 방법을 KLD에 적용해 식을 정리하면 다음과 같습니다.


$$
\begin{align*}
{ D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right)  \right) =&{ D }_{ KL }\left( q\left( z \right) ||p\left( z \right)  \right) +\log { p\left( x \right)  } -{ E }_{ z\sim q\left( z \right)  }\left[ \log { p(x|z) }  \right] \\ =&{ E }_{ z\sim q\left( z \right)  }\left[ \log { \frac { q\left( z \right)  }{ p\left( z \right)  }  }  \right] +\log { p\left( x \right)  } -{ E }_{ z\sim q\left( z \right)  }\left[ \log { p(x|z) }  \right] \\ \approx &\frac { 1 }{ K } \sum _{ i=0 }^{ K }{ { \left[ \log { \frac { q\left( { z }_{ i } \right)  }{ p\left( { z }_{ i } \right)  }  }  \right]  }_{ { z }_{ i }\sim q\left( z \right)  } } +\log { p\left( x \right)  } -\frac { 1 }{ K } \sum _{ i=0 }^{ K }{ { \left[ \log { p\left( x|{ z }_{ i } \right)  }  \right]  }_{ { z }_{ i }\sim q\left( z \right)  } } \\ =&\frac { 1 }{ K } \sum _{ i=0 }^{ K }{ { \left[ \log { q\left( { z }_{ i } \right)  } -\log { p\left( { z }_{ i } \right)  } -\log { p\left( x|{ z }_{ i } \right)  }  \right]  }_{ { z }_{ i }\sim q\left( z \right)  } } +\log { p\left( x \right)  } 
\end{align*}
$$


이렇게 되면 $q(z)$를 설정하는 것이 자유롭게 됩니다. 동전던지기 예제에서는 $q(z)$를 베타분포로 정하는 것이 자연스럽지만, 실제 문제에서는 사후확률 분포에 대해 아무런 정보가 없기 때문에 이렇게 VI를 진행하기 어렵습니다. 하지만 몬테카를로 방법을 이용하게 되면 $q(z)$를 어떤 분포든 사용할 수 있게 됩니다. 

예컨대 사후분포에 대한 정보가 없어서 $q(z)$를 정규분포로 정했다고 칩시다. 이 정규분포에서 $K$개의 $z$들을 뽑으면 위 식, 즉 KLD의 근사값을 계산할 수 있게 됩니다. 정규분포의 파라메터는 평균과 분산이므로, 이들을 조금씩 바꿔가면서 KLD 근사값을 최소로 하는 평균과 분산을 구할 수 있을 것입니다. 이렇게 구해진 정규분포가 바로 VI의 결과가 됩니다.





## Variational Inference with SGD

VI에 [그래디언트 디센트(Gradient Descent)](https://ratsgo.github.io/deep%20learning/2017/09/25/gradient/)를 이용할 수도 있습니다. KLD를 줄이는 쪽으로 파라메터를 업데이트한다는 게 핵심 아이디어죠. 이를 **Stochastic Variational Inference**(SVI)라고도 합니다. 어쨌든 이 방식으로 VI를 하려면 KLD 식이 미분 가능해야 합니다. $q(z)$는 정규분포($θ_q=\{μ_q, σ_q\}$), $p(z)$는 베타분포($α$, $β$)라고 두고 KLD 식을 $θ_q$에 대해 미분해 보겠습니다. (추론 대상 파라메터는 $θ_q$)


$$
\begin{align*}
\frac { \partial  }{ \partial { \theta  }_{ q } } { D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right)  \right) =&\frac { \partial  }{ \partial { \theta  }_{ q } } { D }_{ KL }\left( q\left( z \right) ||p\left( z \right)  \right) +\frac { \partial  }{ \partial { \theta  }_{ q } } \log { p\left( x \right)  } -\frac { \partial  }{ \partial { \theta  }_{ q } } { E }_{ z\sim q\left( z \right)  }\left[ \log { p(x|z) }  \right] \\ =&\frac { \partial  }{ \partial { \theta  }_{ q } } { E }_{ z\sim q\left( z \right)  }\left[ \log { q\left( z \right)  } -\log { p\left( z \right)  } -\log { p(x|z) }  \right] 
\end{align*}
$$


위 식 미분을 완료하려면 $d/dθ_q$가 *expectaion* 안으로 들어가야 합니다. 그런데 $q(z)$는 $θ_q$에 의존하는 분포이고 $z$는 $q$에서 뽑기 때문에 $d/dθ_q$가 *expectaion* 안으로 들어갈 수 없음을 확인할 수 있습니다.

이렇게 하면 어떨까요? **$z$ 대신 노이즈($ε$)를 뽑고, 노이즈로부터 $z$를 계산한다.** $q(z)$는 정규분포라고 가정했으므로, $z$는 다음과 같이 쓸 수 있습니다.


$$
z={ \mu  }_{ q }+{ \sigma  }_{ q }\epsilon ,\quad \epsilon \sim N\left( 0,1 \right) 
$$


따라서 위의 식은 다음과 같이 전개할 수 있습니다. $E_{ε~N(0,1)}$은 더 이상 $θ_q$에 의존하지 않으므로 $d/dθ_q$가 *expectaion* 안으로 들어갈 수 있습니다. SVI 역시 몬테카를로 방법을 써서 $K$개 샘플로 KLD 함수의 그래디언트를 근사할 수 있습니다. 이 그래디언트의 반대 방향으로 파라메터 $θ_q$를 조금씩 업데이트하면 KLD를 줄일 수 있게 되고, 이를 반복하게 되면 사후확률 분포 $p(z$\|$x)$에 근사하는 $q(z)$를 찾을 수 있습니다.


$$
\begin{align*}
\frac { \partial  }{ \partial { \theta  }_{ q } } { D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right)  \right) =&\frac { \partial  }{ \partial { \theta  }_{ q } } { E }_{ \varepsilon \sim N\left( 0,1 \right)  }\left[ \log { q\left( { \mu  }_{ q }+{ \sigma  }_{ q }\varepsilon  \right)  } -\log { p\left( { \mu  }_{ q }+{ \sigma  }_{ q }\varepsilon  \right)  } -\log { p(x|z={ \mu  }_{ q }+{ \sigma  }_{ q }\varepsilon ) }  \right] \\ =&{ E }_{ \varepsilon \sim N\left( 0,1 \right)  }\left[ \frac { \partial  }{ \partial { \theta  }_{ q } } \left\{ \log { q\left( { \mu  }_{ q }+{ \sigma  }_{ q }\varepsilon  \right)  } -\log { p\left( { \mu  }_{ q }+{ \sigma  }_{ q }\varepsilon  \right)  } -\log { p(x|z={ \mu  }_{ q }+{ \sigma  }_{ q }\varepsilon ) }  \right\}  \right] \\ \approx &\frac { 1 }{ K } \sum _{ i=0 }^{ K }{ { \left[ \log { q\left( { \mu  }_{ q }+{ \sigma  }_{ q }{ \varepsilon  }_{ i } \right)  } -\log { p\left( { \mu  }_{ q }+{ \sigma  }_{ q }{ \varepsilon  }_{ i } \right)  } -\log { p(x|z={ \mu  }_{ q }+{ \sigma  }_{ q }{ \varepsilon  }_{ i }) }  \right]  }_{ { \varepsilon  }_{ i }\sim N\left( 0,1 \right)  } } 
\end{align*}
$$


노이즈($ε$)를 뽑아 VI를 하는 방식은 $z$를 직접 샘플링하는 방식보다 분산(variance)이 적어 유용하다고 합니다.





## Vatiational EM algorithm

지금까지는, 사전확률함수 $p(z)$와 우도함수 $p(x$\|$z)$를 이미 알고 있다는 전제 하에 VI 과정을 설명해 드렸습니다. 하지만 실제 문제에서는 사전확률과 우도의 파라메터 또한 알고 있지 못하는 경우가 많습니다. 그런데 VI는 사후확률 $p(z$\|$x)$에 근사한 $q(z)$를 찾는 것이 목적이므로 $p(z)$의 파라메터는 임의로 고정시켜도 관계 없다고 합니다. (아래 식에서 상수항인 $\log{p(x)}$에 해당) 

따라서 우리는 사후확률 $p(z$\|$x)$에 근사한 $q(z)$의 파라메터를 찾는 것과 동시에, 우도함수 $p(x$\|$z)$의 파라메터 또한 추정해야 합니다. 하지만 이를 단박에 찾기 어렵습니다. 이 때 유용한 방법론이 바로 **EM algorithm**입니다. $q(z)$의 파라메터를 $θ_q$, 우도함수의 파라메터를 $θ_l$라고 둘 때 EM algorithm은 다음과 같은 과정을 수렴할 때까지 반복합니다.

- **Expectaion** : $D_{KL}(q(z)$\|\|$p(z$\|$x))$를 줄이는 $θ_q$를 찾는다. (몬테카를로 방법을 활용한 VI, SVI 등 적용)
- **Maximization** : *E-step*에서 찾은 $θ_q$를 고정한 상태에서 $\log{p(x)}$의 하한(lower bound)을 최대화하는 $p(x$\|$z)$의 파라메터 $θ_l$를 찾는다.

여기에서 생소한 내용이 *M-step*입니다. 우선 KLD는 다음 식의 우변과 같이 세 개 요소로 분해될 수 있습니다. *E-step*에서는 KLD를 줄이기 위해 $q$만을 업데이트하므로 이 과정에서 $\log{p(x)}$는 변하지 않습니다. 그런데 KLD를 줄이기 위해선 $\log{p(x)}$ 또한 줄여야 할 것입니다. 


$$
{ D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right)  \right) ={ D }_{ KL }\left( q\left( z \right) ||p\left( z \right)  \right) +\log { p\left( x \right)  } -{ E }_{ z\sim q\left( z \right)  }\left[ \log { p(x|z) }  \right]
$$


위 식을 $\log{p(x)}$를 중심으로 정리하면 다음과 같이 쓸 수 있습니다.


$$
\log { p\left( x \right)  } ={ E }_{ z\sim q\left( z \right)  }\left[ \log { p(x|z) }  \right] -{ D }_{ KL }\left( q\left( z \right) ||p\left( z \right)  \right) +{ D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right)  \right)
$$


KLD는 항상 양수입니다.


$$
{ D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right)  \right) \ge 0
$$


따라서 $\log{p(x)}$의 하한은 다음과 같습니다. $p(x)$는 베이즈 정리에서 *evidence*라고 이름이 붙여진 항인데요. 이 때문에 아래 부등식의 우변을 **Evidence Lower Bound**(ELBO)라고도 부릅니다.




$$
\log { p\left( x \right)  } \ge { E }_{ z\sim q\left( z \right)  }\left[ \log { p(x|z) }  \right] -{ D }_{ KL }\left( q\left( z \right) ||p\left( z \right)  \right) 
$$


위 부등식 우변의 값을 줄이게 된다면 $\log{p(x)}$를 줄이게 되고, 결과적으로 KLD를 줄일 수 있게 됩니다. 따라서 $θ_q$를 고정시킨 채 위 부등식 우변의 값을 줄이는 방향으로 우도함수의 파라메터 $θ_l$를 업데이트하면 우리가 원하는 결과를 얻을 수 있습니다.











