---
title: NLP의 기본 절차와 Lexical Analysis
category: Natural Language Processing
tag: Lexical Analysis
---

이번 포스팅에서는 자연언어처리의 기본 절차와 몇 가지 용어에 대해 살펴보도록 하겠습니다. 이번 포스팅은 기본적으로 [고려대 강필성 교수님](https://github.com/pilsung-kang/text-mining)과 역시 같은 대학의 정순영 교수님 강의를 참고했음을 먼저 밝힙니다. 그럼 시작하겠습니다.



# 자연언어처리의 기본 절차

<a href="http://imgur.com/1bhgstG"><img src="http://i.imgur.com/1bhgstG.png" width="500px" title="source: imgur.com" /></a>

자연언어처리의 전반적인 절차를 간략하게 시각화한 것은 위 그림과 같습니다. 자연언어처리는 우선 언어학을 근간으로 하고 있습니다. 주지하다시피 언어학은 말소리를 연구하는 **음운론(Phonology)**, [단어](https://ratsgo.github.io/korean%20linguistics/2017/04/10/word/)와 [형태소](https://ratsgo.github.io/korean%20linguistics/2017/03/20/morpheme/)를 연구하는 **형태론(Morphology)**, 문법과 맥락/담화를 각각 논의하는 **통사론(syntax)**, **의미론(Senmantics)** 등 세부 분야가 있는데요. 자연언어처리 절차와 단계도 이런 구분과 궤를 같이 합니다. 다시 말해 음성 인식, 형태소 분석, 파싱(문장의 문법적 구조 분석) 등이 각각 언어학의 음운/형태/통사론 등에 대응된다는 얘기입니다. 구체적인 분석 과정을 도표로 정리한 그림은 다음과 같습니다.

<a href="https://imgur.com/KgyPoG1"><img src="https://i.imgur.com/KgyPoG1.png" width="500px" title="source: imgur.com" /></a>

과정별로 나타낸 그림은 다음과 같습니다.

<a href="https://imgur.com/jxZnuyN"><img src="https://i.imgur.com/jxZnuyN.png" width="500px" title="source: imgur.com" /></a>

이번 글에서는 **어휘분석(Morphological and lexcical analysis)** 중심으로 이야기를 해보겠습니다. 



# 어휘분석(Lexical Analysis)

어휘 분석을 한눈에 조망할 수 있는 그림이 바로 아래 예시입니다. 

<a href="http://imgur.com/lpuN4IT"><img src="http://i.imgur.com/lpuN4IT.png" width="600px" title="source: imgur.com" /></a>

**포스태깅(Part of speech)**는 단어의 품사 정보를 결정하는 절차이며 **개체명 인식(Named entity recognition)**은 인명, 지명 등 고유명사를 분류하는 방법론입니다. **상호참조(co-reference)**는 선행 단어/구를 현재 단어/구와 비교해 같은 개체인지를 결정하는 문제입니다. **의존관계 분석(basic dependencies)**은 성분에 따라 문장구조를 정의하는 구구조문법(생성문법 기반)과 달리 단어와 다른 단어가 가지는 의존관계를 중시해 문장 구조를 분석하는 방법입니다. 이들 넷은 모두 어휘분석의 하위 범주로 언어학, 통계학, 수학, 컴퓨터사이언스 등 다양한 분야의 학자들이 꽤 많은 성과를 낸 영역입니다. 사실 자연언어처리는 이들 영역이 모두 겹쳐있는 융합학문입니다.

<a href="http://imgur.com/5eyQgSs"><img src="http://i.imgur.com/5eyQgSs.png" width="400px" title="source: imgur.com" /></a>




# 어휘분석 절차

이번 챕터에서는 어휘분석 절차에 대해 이야기해보겠습니다. 크게 **문장분리(sentence splitting)**, **토크나이즈(tokenize), Morphological analysis**, **포스태깅** 네 단계로 나뉩니다.



## Sentence splitting

컴퓨터 입장에서 **말뭉치(corpus)**는 의미없는 글자들의 나열일 겁니다. 우선 이를 문장 단위로 끊어서 입력해야 합니다. 일반적으로는 마침표(.)나 느낌표(!), 물음표(?) 등 기준으로도 충분히 문장분리를 잘 수행할 수 있습니다. 하지만 토픽모델링 같은 특정 알고리즘이나 방법론의 경우 문장분리를 반드시 수행하지 않아도 됩니다.



## Tokenize

**토큰(token)**이란 의미를 가지는 문자열을 뜻합니다. 토큰은 형태소(뜻을 가진 최소 단위)나 그보다 상위 개념인 **단어**(자립하여 쓸 수 있는 최소 단위)까지 포함합니다. **토크나이징(tokenizing)**이란 문서나 문장을 분석하기 좋도록 토큰으로 나누는 작업입니다. 영어의 경우 공백만으로도 충분히 토큰을 나눌 수 있다고 합니다. 물론 '-'(state-of-the-art vs state of the art)이나 합성어(Barack Obama) 등 처리를 세밀히 해줘야 하는 문제가 남아있긴 하지만요. 띄어쓰기를 거의 하지 않는 중국어의 경우 토큰 분석 작업이 난제로 꼽힙니다.



## Morphological analysis

**Text Normaization**이라고 불리기도 합니다. 토큰들을 좀 더 일반적인 형태로 분석해 단어수를 줄여 분석의 효율성을 높이는 작업입니다. 예컨대 'cars'와 'car', 'stopped'와 'stop'을 하나의 단어로 본다던지 하는 식입니다. 영어에선 대문자를 소문자로 바꿔주는 **folding**도 이와 관련된 중요한 작업이라고 하네요. **stemming**과 **lemmatization**이라는 작업도 있습니다. stemming이란 단어를 축약형으로 바꿔주는 걸 뜻하고, lemmatization은 품사 정보가 보존된 형태의 기본형으로 변환하는 걸 말합니다. 아래 표가 두 기법 차이를 잘 드러내고 있습니다.

|    Word     | stemming | lemmatization |
| :---------: | :------: | :-----------: |
|    Love     |   Lov    |     Love      |
|    Loves    |   Lov    |     Love      |
|    Loved    |   Lov    |     Love      |
|   Loving    |   Lov    |     Love      |
| Innovation  | Innovat  |  Innovation   |
| Innovations | Innovat  |  Innovation   |
|  Innovate   | Innovat  |   Innovate    |
|  Innovates  | Innovat  |   Innovate    |
| Innovative  | Innovat  |  Innovative   |



## Part-Of-Speech Tagging

포스태깅이란 토큰의 품사정보를 할당하는 작업입니다. 지금까지 많은 방법론들이 개발되었는데요. 의사결정나무(Decision Trees), 은닉 마코프 모델(Hidden Markov Models), 서포트벡터머신(Support Vector Machines) 등이 여기에 해당합니다. [KoNLPy](http://konlpy.org) 같은 한국어 기반의 포스태거들은 문장분리, 토크나이즈, lemmatization, 포스태깅에 이르기까지 전 과정을 한꺼번에 수행해 줍니다.

하지만 조사, 어미가 발달한 한국어의 경우 정확한 분석이 정말 어렵습니다. 한국어는 **교착어** 성질을 지니는 언어이기 때문입니다. 즉 **어근**에 파생접사나 어미가 붙어서 단어를 이룹니다. 바꿔 말하면 한국어를 분석할 때 어근과 접사, 어미를 적절하게 나누어야 하는데, 이게 쉽지 않다는 얘기입니다. 예를 들면 이렇습니다.

> 깨뜨리시었겠더군요.

여기에서 '깨-'는 어근이며, '-뜨리-'는 접사로서 '힘줌'의 뜻을 나타냅니다. '-시-'는 높임, '-었-', '-겠-', '-더-'는 모두 시간을 보이는 어미들이며, '-군-'은 감탄의 뜻을 나타내는 어미, '-요'는 문장을 끝맺는 어미입니다. 위 문장을 제대로 분석하려면 8개 형태소로 쪼개야 합니다. 매우 고된 작업이지요.



## 마치며

이상으로 자연언어처리의 기본 절차를 어휘분석 중심으로 살펴보았습니다. 정리하면서 느낀 건데 단어와 형태소 분석이 자연언어처리의 기본 중 기본 아닐까 하는 생각이 듭니다. 이 작업이 신통치 않다면 이를 기반으로 하는 파싱(문장 구조 분석) 등 이후 과정의 신뢰도가 무너지게 될 겁니다. 더 나은 방법이 없을까 늘 고민해보겠습니다. 여기까지 읽어주셔서 감사합니다.

