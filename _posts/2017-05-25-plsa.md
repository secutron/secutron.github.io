---
title: Probabilistic Latent Semantic Analysis
category: From frequency to semantics
tag: pLSA
---

이번 글에서는 말뭉치에 내재해 있는 토픽들을 추론해 내는 확률모델인 **Probabilistic Latent Semantic Analysis(pLSA)**에 대해 살펴보도록 하겠습니다. 이번 글 역시 고려대 강필성 교수님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.



## LSA

pLSA는 기존 **잠재의미분석(Latene Semantic Analysis)**과는 아예 다른 기법이지만 개념을 공유하는게 많아서 먼저 설명해볼까 합니다. LSA에 대한 자세한 내용은 [이곳](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/04/06/pcasvdlsa/)을 참고하시면 좋을 것 같습니다. 어쨌든 LSA는 말뭉치 행렬 $A$를 다음과 같이 분해하는 걸 말합니다.

<a href="http://imgur.com/YnroTPH"><img src="http://i.imgur.com/YnroTPH.png" width="500px" title="source: imgur.com" /></a>

LSA 수행 결과로 $n$개 문서가 원래 단어 개수보다 훨씬 작은 $q$차원의 벡터로 표현된 걸 확인할 수 있습니다. 마찬가지로 $m$개 단어는 원래 문서 수보다 훨씬 작은 $q$차원 벡터로 변환됐습니다.  $q$가 3이라면 전체 말뭉치가 3개의 토픽으로 분석됐다고도 말할 수 있을 것입니다.

위 그림에서 행렬 $L$의 열벡터는 각각 해당 토픽에 대한 문서들의 분포 정보를 나타냅니다. $R$의 행벡터는 각각 해당 토픽에 대한 단어들의 분포 정보를 나타냅니다. 중간에 대각행렬은 $q$개 토픽 각각이 전체 말뭉치 내에서 얼마나 중요한지 나타내는 가중치가 될 겁니다.



## pLSA

pLSA는 단어와 문서 사이를 잇는, 우리 눈에 보이지 않는 잠재구조가 있다는 가정 하에 단어와 문서 출현 확률을 모델링한 확률모형입니다. pLSA는 아래 그림처럼 **Latent concepts**가 존재하고 이것이 문서와 단어를 연결한다고 가정합니다. 문서들의 주제(토픽)이라고 생각하면 좋을 것 같습니다.

<a href="http://imgur.com/hiVmhJc"><img src="http://i.imgur.com/hiVmhJc.png" width="450px" title="source: imgur.com" /></a>

왼쪽부터 차례로 살펴보겠습니다. P(z\|d)는 문서 하나가 주어졌을 때 특정 주제(토픽)가 나타날 확률을 의미합니다. P(w\|z)는 주제가 정해졌을 때 특정 단어가 나타날 확률을 가리킵니다. 

예컨대 위 그림 기준에서 네번째 문서는 trade라는 주제로만 구성돼 있습니다. 그런데 trade라는 주제는 economic, imports, trade 따위의 단어를 선호하네요. 

결과적으로 네번째 문서에는 economic, imports, trade 등의 단어가 출현할 가능성이 높다고 할 수 있겠습니다. pLSA의 가정에 문제가 없다면 해당 문서에 실제 등장하는 단어의 출현 확률은 높아야 할 겁니다.

그럼 pLSA가 가정하는 단어-문서 생성 과정을 살펴보겠습니다. 아래 그림을 볼까요?

<a href="http://imgur.com/BXijX5M"><img src="http://i.imgur.com/BXijX5M.png" width="550px" title="source: imgur.com" /></a>

(a) 먼저 보겠습니다. 우선 문서를 뽑습니다. 그 다음 이 문서의 주제를 뽑습니다. 마지막으로 해당 주제별로 단어를 뽑습니다. 사람이 글 쓸 때도 글을 쓰기로 마음을 먹고 나서 주제, 단어를 차례대로 결정하기 때문에 직관적으로 이해가 가능합니다.

그런데 (b)는 좀 이해하기 까다롭습니다. 주제(z)를 뽑은 뒤 이 주제에 해당하는 문서와 단어를 뽑는 방식입니다. pLSA는 바로 이 방식으로 모델이 구성돼 있습니다.



## LSA와 pLSA

LSA는 행렬 인수분해(matrix factorization), pLSA는 확률모형입니다. 아예 그 종류가 다르다고 할 수 있죠. 하지만 개념상 연결되는 부분이 있습니다. 그래서일까요? 이름도 좀 많이 비슷해요. 어쨌든 아래 그림을 보겠습니다.

<a href="http://imgur.com/cHbHrOw"><img src="http://i.imgur.com/cHbHrOw.png" width="400px" title="source: imgur.com" /></a>



LSA 결과물인 행렬 $U_k$의 열벡터는 각각 해당 토픽에 대한 문서들의 분포 정보를 나타냅니다. 이는 pLSA의 P(d\|z)에 대응합니다.

행렬 $V_k$의 행벡터는 각각 해당 토픽에 대한 단어들의 분포 정보를 나타냅니다.이는 pLSA의 P(w\|z)에 대응합니다.

$Σ_k$의 대각성분은 토픽 각각이 전체 말뭉치 내에서 얼마나 중요한지 나타내는 가중치가 됩니다. 이는 pLSA의 P(z)에 대응합니다.

pLSA의 결과물은 확률이기 때문에 각 요소값이 모두 0 이상, 전체 합이 1이 됩니다. 하지만 LSA는 이런 조건을 만족하지 않습니다.



## pLSA의 목적식

pLSA는 $m$개 단어, $n$개 문서, $k$개 주제(토픽)에 대해 아래 우도함수를 최대화하는 걸 목표로 합니다.
$$
\begin{align*}
L&=\coprod _{ i=1 }^{ m }{ \coprod _{ j=1 }^{ n }{ { p({ w }_{ i },{ d }_{ j }) }^{ n({ w }_{ i },{ d }_{ j }) } }  } \\ &=\coprod _{ i=1 }^{ m }{ \coprod _{ j=1 }^{ n }{ { \left\{ \sum _{ l=1 }^{ k }{ p({ d }_{ j }|{ z }_{ l })p({ z }_{ l })p({ w }_{ i }|z_{ l }) }  \right\}  }^{ n({ w }_{ i },{ d }_{ j }) } }  } 
\end{align*}
$$


위 식에서 $n(w_i,d_j)$는 $j$번째 문서에 $i$번째 단어가 등장한 횟수를 나타냅니다. $p(w_i, d_j)$는 $k$개 주제(토픽)에 대해 summation 형태로 돼 있는데요. 같은 단어라 하더라도 여러 토픽에 쓰일 수 있기 때문입니다. 예컨대 정부(government) 같은 흔한 단어는 정치, 경제, 외교/국방 등 다양한 주제에 등장할 수 있습니다.



## pLSA의 학습 : EM 알고리즘

**EM알고리즘**은 동시에 최적화할 수 없는 복수의 변수들을 반복적인 방식으로 계산하는 기법입니다. 우선 모든 값을 랜덤으로 초기화합니다. 이후 하나의 파라메터를 고정시킨 다음에 다른 파라메터를 업데이트하고, 이후 단계에선 업데이트된 파라메터로 고정시킨 파라메터를 다시 업데이트합니다. 다음과 같습니다.

<a href="http://imgur.com/lNIYsxF"><img src="http://i.imgur.com/lNIYsxF.png" title="source: imgur.com" /></a>



## 분석 예시

다음과 같은 Term-Document Matrix를 분석해 보겠습니다.

|    word    | Doc 1 | Doc 2 | Doc 3 | Doc 4 | Doc 5 | Doc 6 |
| :--------: | :---: | :---: | :---: | :---: | :---: | :---: |
|  Baseball  |   1   |   2   |   0   |   0   |   0   |   0   |
| Basketball |   3   |   1   |   0   |   0   |   0   |   0   |
|   Boxing   |   2   |   0   |   0   |   0   |   0   |   0   |
|   Money    |   3   |   3   |   2   |   3   |   2   |   4   |
|  Interest  |   0   |   0   |   3   |   2   |   0   |   0   |
|    Rate    |   0   |   0   |   4   |   1   |   0   |   0   |
|  Democrat  |   0   |   0   |   0   |   0   |   4   |   3   |
| Republican |   0   |   0   |   0   |   0   |   2   |   1   |
|   Cocus    |   0   |   0   |   0   |   0   |   3   |   2   |
| President  |   0   |   0   |   1   |   0   |   2   |   3   |

pLSA 수행 결과로 계산된 P(z)는 다음과 같습니다.

| Topic 1 | Topic 2 | Topic 3 |
| :-----: | :-----: | :-----: |
|  0.456  |  0.281  |  0.263  |

P(d\|z)는 다음과 같습니다. 이 결과로 미루어 짐작해볼 때 Topic1은 정치, Topic2는 경제, Topic3는 스포츠인 것 같습니다.

| Docs  | Topic 1 | Topic 2 | Topic 3 |
| :---: | :-----: | :-----: | :-----: |
| Doc 1 |  0.000  |  0.000  |  0.600  |
| Doc 2 |  0.000  |  0.000  |  0.400  |
| Doc 3 |  0.000  |  0.625  |  0.000  |
| Doc 4 |  0.000  |  0.375  |  0.000  |
| Doc 5 |  0.500  |  0.000  |  0.000  |
| Doc 6 |  0.500  |  0.000  |  0.000  |

P(w\|z)는 다음과 같습니다.

|   Terms    | Topic 1 | Topic 2 | Topic 3 |
| :--------: | :-----: | :-----: | :-----: |
|  Baseball  |  0.000  |  0.000  |  0.200  |
| Basketball |  0.000  |  0.000  |  0.267  |
|   Boxing   |  0.000  |  0.000  |  0.133  |
|   Money    |  0.231  |  0.313  |  0.400  |
|  Interest  |  0.000  |  0.312  |  0.000  |
|    Rate    |  0.000  |  0.312  |  0.000  |
|  Democrat  |  0.269  |  0.000  |  0.000  |
| Republican |  0.115  |  0.000  |  0.000  |
|   Cocus    |  0.192  |  0.000  |  0.000  |
| President  |  0.192  |  0.063  |  0.000  |

pLSA 수행 결과로 나온 표들은 겉보기에는 LSA의 행렬 인수분해 결과와 흡사해 보입니다. 하지만 주의할 것은 도출되는 과정 자체가 확률모형을 전제했다는 것입니다.



## 코드

pLSA를 R로 직접 구현해 봤습니다. 다음과 같습니다.

<script src="https://gist.github.com/ratsgo/c25deb6d79f3ab8b0b050af751fbbdb8.js"></script>